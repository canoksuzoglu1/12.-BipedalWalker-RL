{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db3c3cc",
   "metadata": {},
   "source": [
    "# **Table of Contents**\n",
    "\n",
    "### 1. **Import Libraries**  \n",
    "   - 1A. [Import Required Libraries](#1a-import-required-libraries)  \n",
    "   - 1B. [Create Environment and Test](#1b-create-environment-and-test)  \n",
    "\n",
    "### 2. **Train Model for Normal Version with PPO**  \n",
    "   - 2A. [Train the Model](#2a-train-the-model)  \n",
    "   - 2B. [Save the Model](#2b-save-the-model)  \n",
    "   - 2C. [Evaluate the Model](#2c-evaluate-the-model)  \n",
    "\n",
    "### 3. **Train Model for Hardcore Version with PPO**  \n",
    "   - 3A. [Test the Environment](#3a-test-the-environment)  \n",
    "   - 3B. [Train the Hardcore Model](#3b-train-the-hardcore-model)  \n",
    "   - 3C. [Save the Hardcore Model](#3c-save-the-hardcore-model)  \n",
    "   - 3D. [Evaluate the Hardcore Model](#3d-evaluate-the-hardcore-model)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710222a0",
   "metadata": {},
   "source": [
    "# 1. Import Libaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c4e23c",
   "metadata": {},
   "source": [
    "## 1A) Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38945631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "# gymnasium is a modern version of the gym library used to create and interact with reinforcement learning environments\n",
    "import gymnasium as gym\n",
    "\n",
    "# Import PPO (Proximal Policy Optimization) from stable-baselines3, which is a popular RL algorithm\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Import the evaluation function to assess the performance of the trained policy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070346c",
   "metadata": {},
   "source": [
    "## 1B) Create Env and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BipedalWalker environment with human-rendering mode enabled\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment (start a new episode) - without using seed or options\n",
    "obs = env.reset()\n",
    "\n",
    "# Let the agent take random actions for 1000 steps\n",
    "for _ in range(1000):\n",
    "    # Take a random action sampled from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Step the environment forward using the chosen action\n",
    "    # The environment returns the new observation (obs), the reward, \n",
    "    # whether the episode is done (done), if it was truncated (truncated), and additional info (info)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # If the episode is finished (either done or truncated), reset the environment for a new episode\n",
    "    if done or truncated:\n",
    "        obs = env.reset()\n",
    "\n",
    "# Close the environment when finished to clean up resources\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9a69c",
   "metadata": {},
   "source": [
    "# 2) Train Model for Normal Version with PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402a0f9",
   "metadata": {},
   "source": [
    "## 2A) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PPO model with a Multi-Layer Perceptron (MLP) policy\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a70bb",
   "metadata": {},
   "source": [
    "## 2B) Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d758bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo_bipedalwalker_1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17b95a",
   "metadata": {},
   "source": [
    "## 2C) Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_bipedalwalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli değerlendirin (örneğin, 10 bölüm boyunca)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "print(f\"Ortalama ödül: {mean_reward} ± {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0349ec6b",
   "metadata": {},
   "source": [
    "# 3) Train Model for Hardcore Version with PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a40c21",
   "metadata": {},
   "source": [
    "## 3A) Test Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", hardcore=True, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment (start a new episode) - without using seed or options\n",
    "obs = env.reset()\n",
    "\n",
    "# Let the agent take random actions for 1000 steps\n",
    "for _ in range(1000):\n",
    "    # Take a random action sampled from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Step the environment forward using the chosen action\n",
    "    # The environment returns the new observation (obs), the reward, \n",
    "    # whether the episode is done (done), if it was truncated (truncated), and additional info (info)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # If the episode is finished (either done or truncated), reset the environment for a new episode\n",
    "    if done or truncated:\n",
    "        obs = env.reset()\n",
    "\n",
    "# Close the environment when finished to clean up resources\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b7cbf",
   "metadata": {},
   "source": [
    "## 3B) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c74594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PPO model with a Multi-Layer Perceptron (MLP) policy\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf351e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", hardcore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662adcb6",
   "metadata": {},
   "source": [
    "## 3C) Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddcb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo_bipedalwalker_hardcore_3M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0059a",
   "metadata": {},
   "source": [
    "## 3D) Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eced13",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", hardcore=True, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli değerlendirin (örneğin, 10 bölüm boyunca)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "print(f\"Ortalama ödül: {mean_reward} ± {std_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
