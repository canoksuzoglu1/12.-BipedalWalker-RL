{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f2f519",
   "metadata": {},
   "source": [
    "# 1. Import Libaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616732c",
   "metadata": {},
   "source": [
    "## 1A) Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38945631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "# gymnasium is a modern version of the gym library used to create and interact with reinforcement learning environments\n",
    "import gymnasium as gym\n",
    "\n",
    "# Import PPO (Proximal Policy Optimization) from stable-baselines3, which is a popular RL algorithm\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Import the evaluation function to assess the performance of the trained policy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22670a21",
   "metadata": {},
   "source": [
    "## 1B) Create Env and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BipedalWalker environment with human-rendering mode enabled\n",
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment (start a new episode) - without using seed or options\n",
    "obs = env.reset()\n",
    "\n",
    "# Let the agent take random actions for 1000 steps\n",
    "for _ in range(1000):\n",
    "    # Take a random action sampled from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Step the environment forward using the chosen action\n",
    "    # The environment returns the new observation (obs), the reward, \n",
    "    # whether the episode is done (done), if it was truncated (truncated), and additional info (info)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # If the episode is finished (either done or truncated), reset the environment for a new episode\n",
    "    if done or truncated:\n",
    "        obs = env.reset()\n",
    "\n",
    "# Close the environment when finished to clean up resources\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146b579",
   "metadata": {},
   "source": [
    "# 2) Train Model for Normal Version with PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1791c",
   "metadata": {},
   "source": [
    "## 2A) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PPO model with a Multi-Layer Perceptron (MLP) policy\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e58457",
   "metadata": {},
   "source": [
    "## 2B) Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d758bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo_bipedalwalker_1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e73b66",
   "metadata": {},
   "source": [
    "## 2C) Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_bipedalwalker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli değerlendirin (örneğin, 10 bölüm boyunca)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "print(f\"Ortalama ödül: {mean_reward} ± {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43256982",
   "metadata": {},
   "source": [
    "# 3) Train Model for Hardcore Version with PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f606f63",
   "metadata": {},
   "source": [
    "## 3A) Test Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", hardcore=True, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c09e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment (start a new episode) - without using seed or options\n",
    "obs = env.reset()\n",
    "\n",
    "# Let the agent take random actions for 1000 steps\n",
    "for _ in range(1000):\n",
    "    # Take a random action sampled from the environment's action space\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Step the environment forward using the chosen action\n",
    "    # The environment returns the new observation (obs), the reward, \n",
    "    # whether the episode is done (done), if it was truncated (truncated), and additional info (info)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # If the episode is finished (either done or truncated), reset the environment for a new episode\n",
    "    if done or truncated:\n",
    "        obs = env.reset()\n",
    "\n",
    "# Close the environment when finished to clean up resources\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66029faa",
   "metadata": {},
   "source": [
    "## 3B) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PPO model with a Multi-Layer Perceptron (MLP) policy\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a76fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", hardcore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfedf0",
   "metadata": {},
   "source": [
    "## 3C) Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d8d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo_bipedalwalker_hardcore_3M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15863930",
   "metadata": {},
   "source": [
    "## 3D) Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\", hardcore=True, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli değerlendirin (örneğin, 10 bölüm boyunca)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "print(f\"Ortalama ödül: {mean_reward} ± {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2eefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
